from core.llm.gemini import GeminiLLM, GeminiStreamingLLM
from core.classifier.medical_classifier import MedicalClassifier
from core.vector_store.enhanced_vector_store import EnhancedVectorStore
from core.vector_store.embeddings import SentenceTransformerEmbeddings
from core.data.web_data_manager import WebDataManager
from config.prompts import MEDICAL_SYSTEM_PROMPT
from langchain.memory import ConversationBufferWindowMemory
from langchain.chains import ConversationalRetrievalChain
from langchain_core.prompts import PromptTemplate
import logging
from config.settings import GEMINI_API_KEY
from typing import Dict, List, Optional, Tuple
logger = logging.getLogger("enhanced_medical_chatbot")

class EnhancedMedicalChatbot:
    def __init__(self):
        self.medical_classifier = MedicalClassifier()
        self.web_data_manager = WebDataManager()
        self.embeddings = SentenceTransformerEmbeddings()
        self.vector_store = EnhancedVectorStore(self.embeddings)
        self.llm = GeminiLLM()
        self.streaming_llm = GeminiStreamingLLM()
        self.memory = ConversationBufferWindowMemory(
            k=6,
            memory_key="chat_history",
            output_key="answer",  # ThÃªm output_key Ä‘á»ƒ chá»‰ Ä‘á»‹nh rÃµ key Ä‘áº§u ra
            return_messages=True
        )
        self.rag_chain = None
        self.suggestion_chain = None
        self.setup_chains()
    
    def setup_chains(self):
        web_data = self.web_data_manager.get_web_data()
        self.vector_store.build_from_web_data(web_data)
        
        if self.vector_store.vectorstore is not None:
            retriever = self.vector_store.as_retriever(search_kwargs={"k": 20})
            prompt_template = PromptTemplate(
                input_variables=["context", "chat_history", "question"],
                template=MEDICAL_SYSTEM_PROMPT
            )
            self.rag_chain = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=retriever,
                memory=self.memory,
                return_source_documents=True,
                combine_docs_chain_kwargs={"prompt": prompt_template},
                output_key="answer"  # Äáº£m báº£o output_key Ä‘Æ°á»£c Ä‘áº·t Ä‘Ãºng
            )
            logger.info("RAG chain initialized successfully")
        else:
            logger.warning("Vector store not available, using simple LLM chain")
            prompt_template = PromptTemplate(
                input_variables=["chat_history", "question"],
                template="""Báº¡n lÃ  trá»£ lÃ½ y táº¿. 
                Chat history: {chat_history}
                Human: {question}
                Assistant:"""
            )
            self.rag_chain = prompt_template | self.llm
        
        suggestion_prompt = PromptTemplate(
            input_variables=["original_question"],
            template="""NgÆ°á»i dÃ¹ng vá»«a há»i: "{original_question}"
            Tuy nhiÃªn cÃ¢u há»i nÃ y khÃ´ng thuá»™c lÄ©nh vá»±c y táº¿.
            HÃ£y Ä‘á» xuáº¥t 1 cÃ¢u há»i tÆ°Æ¡ng tá»± nhÆ°ng liÃªn quan Ä‘áº¿n y táº¿.
            Tráº£ lá»i báº±ng 1 cÃ¢u há»i duy nháº¥t, tiáº¿ng Viá»‡t:"""
        )
        self.suggestion_chain = suggestion_prompt | self.llm
    
    def refresh_data(self):
        logger.info("Refreshing web data...")
        self.web_data_manager.last_update = 0
        self.setup_chains()
    
    def get_health_status(self):
        """Get system health status"""
        return {
            "status": "healthy",
            "model": "gemini-1.5-flash",
            "classifier_loaded": self.medical_classifier.model is not None,
            "vector_store_ready": self.vector_store.vectorstore is not None,
            "rag_chain_ready": self.rag_chain is not None,
            "memory_messages": len(self.memory.chat_memory.messages),
            "api_key_configured": bool(GEMINI_API_KEY)
        }
    def get_smart_context(self, user_message: str) -> str:
        """Láº¥y ngá»¯ cáº£nh thÃ´ng minh dá»±a trÃªn cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng."""
        if self.vector_store.vectorstore is None:
            return "KhÃ´ng cÃ³ thÃ´ng tin bá»• sung"
        
        try:
            # PhÃ¢n tÃ­ch Ã½ Ä‘á»‹nh cÃ¢u há»i
            message_lower = user_message.lower()
            
            # Náº¿u há»i vá» bÃ¡c sÄ© cá»¥ thá»ƒ
            if any(word in message_lower for word in ["bÃ¡c sÄ©", "doctor", "bs"]):
                return self._get_doctor_context(user_message)
            
            # Náº¿u há»i vá» chuyÃªn khoa
            elif any(word in message_lower for word in ["chuyÃªn khoa", "khoa", "specialty"]):
                return self._get_specialty_context(user_message)
            
            # Náº¿u mÃ´ táº£ triá»‡u chá»©ng - tÃ¬m bÃ¡c sÄ© phÃ¹ há»£p
            elif any(word in message_lower for word in ["Ä‘au", "bá»‡nh", "triá»‡u chá»©ng", "khÃ¡m", "chá»¯a"]):
                return self._get_symptom_context(user_message)
            
            # TÃ¬m kiáº¿m thÃ´ng thÆ°á»ng
            else:
                return self._get_general_context(user_message)
                
        except Exception as e:
            logger.warning(f"Smart context error: {e}")
            return self._get_general_context(user_message)

    def _get_doctor_context(self, user_message: str) -> str:
        """Láº¥y ngá»¯ cáº£nh vá» bÃ¡c sÄ©."""
        retriever = self.vector_store.as_retriever(search_kwargs={"k": 15})
        docs = retriever.get_relevant_documents(user_message)
        
        # Æ¯u tiÃªn docs vá» bÃ¡c sÄ© vÃ  chuyÃªn khoa liÃªn quan
        doctor_docs = [doc for doc in docs if doc.metadata.get("type") in ["doctor", "specialty", "specialty_detail"]]
        other_docs = [doc for doc in docs if doc.metadata.get("type") not in ["doctor", "specialty", "specialty_detail"]]
        
        # Káº¿t há»£p Æ°u tiÃªn doctor_docs
        combined_docs = doctor_docs[:10] + other_docs[:5]
        
        return "\n".join([doc.page_content for doc in combined_docs])

    def _get_specialty_context(self, user_message: str) -> str:
        """Láº¥y ngá»¯ cáº£nh vá» chuyÃªn khoa."""
        retriever = self.vector_store.as_retriever(search_kwargs={"k": 15})
        docs = retriever.get_relevant_documents(user_message)
        
        # Æ¯u tiÃªn docs vá» chuyÃªn khoa vÃ  bÃ¡c sÄ© thuá»™c chuyÃªn khoa Ä‘Ã³
        specialty_docs = [doc for doc in docs if doc.metadata.get("type") in ["specialty", "specialty_detail", "doctor"]]
        other_docs = [doc for doc in docs if doc.metadata.get("type") not in ["specialty", "specialty_detail", "doctor"]]
        
        combined_docs = specialty_docs[:12] + other_docs[:3]
        
        return "\n".join([doc.page_content for doc in combined_docs])

    def _get_symptom_context(self, user_message: str) -> str:
        """Láº¥y ngá»¯ cáº£nh khi ngÆ°á»i dÃ¹ng mÃ´ táº£ triá»‡u chá»©ng."""
        # TÃ¬m kiáº¿m rá»™ng hÆ¡n Ä‘á»ƒ bao gá»“m cáº£ bÃ¡c sÄ© vÃ  chuyÃªn khoa
        retriever = self.vector_store.as_retriever(search_kwargs={"k": 20})
        docs = retriever.get_relevant_documents(user_message)
        
        # TÃ¬m thÃªm bÃ¡c sÄ© liÃªn quan
        symptom_keywords = self._extract_symptom_keywords(user_message)
        if symptom_keywords:
            for keyword in symptom_keywords[:2]:  # Chá»‰ láº¥y 2 tá»« khÃ³a chÃ­nh
                extra_docs = retriever.get_relevant_documents(f"bÃ¡c sÄ© chuyÃªn khoa {keyword}")
                docs.extend(extra_docs[:3])
        
        # Loáº¡i bá» duplicate vÃ  Æ°u tiÃªn
        seen_content = set()
        unique_docs = []
        for doc in docs:
            if doc.page_content not in seen_content:
                seen_content.add(doc.page_content)
                unique_docs.append(doc)
        
        return "\n".join([doc.page_content for doc in unique_docs[:15]])

    def _extract_symptom_keywords(self, message: str) -> List[str]:
        """TrÃ­ch xuáº¥t tá»« khÃ³a triá»‡u chá»©ng Ä‘á»ƒ tÃ¬m chuyÃªn khoa phÃ¹ há»£p."""
        symptom_mapping = {
            "tim": ["tim", "trÃ¡i tim", "nhá»‹p tim", "Ä‘au ngá»±c"],
            "gan": ["gan", "máº­t", "vÃ ng da", "Ä‘au bá»¥ng pháº£i"],
            "tháº§n kinh": ["Ä‘áº§u", "nÃ£o", "tháº§n kinh", "tÃª liá»‡t", "chÃ³ng máº·t"],
            "máº¯t": ["máº¯t", "má»", "nhÃ¬n", "thá»‹ lá»±c"],
            "tai mÅ©i há»ng": ["tai", "mÅ©i", "há»ng", "nghe", "nuá»‘t"],
            "da": ["da", "ngá»©a", "ná»•i máº©n", "dá»‹ á»©ng"],
            "xÆ°Æ¡ng khá»›p": ["xÆ°Æ¡ng", "khá»›p", "Ä‘au lÆ°ng", "cá»™t sá»‘ng"],
            "nhi": ["tráº» em", "em bÃ©", "con", "tráº»"],
            "sáº£n phá»¥": ["mang thai", "sinh con", "phá»¥ khoa", "kinh nguyá»‡t"]
        }
        
        message_lower = message.lower()
        keywords = []
        
        for specialty, symptoms in symptom_mapping.items():
            for symptom in symptoms:
                if symptom in message_lower:
                    keywords.append(specialty)
                    break
        
        return list(set(keywords))

    def _get_general_context(self, user_message: str) -> str:
        """Láº¥y ngá»¯ cáº£nh thÃ´ng thÆ°á»ng."""
        retriever = self.vector_store.as_retriever(search_kwargs={"k": 15})
        docs = retriever.get_relevant_documents(user_message)
        return "\n".join([doc.page_content for doc in docs])
    
    # Cáº­p nháº­t phÆ°Æ¡ng thá»©c generate_response Ä‘á»ƒ sá»­ dá»¥ng smart context
    def generate_response(self, user_message: str) -> str:
        """
        Táº¡o pháº£n há»“i khÃ´ng streaming vá»›i ngá»¯ cáº£nh thÃ´ng minh vÃ  gá»£i Ã½ bÃ¡c sÄ©.
        """
        try:
            # Láº¥y ngá»¯ cáº£nh thÃ´ng minh
            context = self.get_smart_context(user_message)
            
            # Láº¥y lá»‹ch sá»­ trÃ² chuyá»‡n
            chat_history = ""
            if self.memory.chat_memory.messages:
                recent_messages = self.memory.chat_memory.messages[-4:]
                for msg in recent_messages:
                    if hasattr(msg, 'content'):
                        role = "Human" if msg.__class__.__name__ == "HumanMessage" else "Assistant"
                        chat_history += f"{role}: {msg.content}\n"

            # Táº¡o prompt vá»›i MEDICAL_SYSTEM_PROMPT
            prompt = MEDICAL_SYSTEM_PROMPT.format(
                context=context,
                chat_history=chat_history,
                question=user_message
            )

            # Gá»i LLM Ä‘á»ƒ táº¡o pháº£n há»“i
            response = self.llm.invoke(prompt)
            if isinstance(response, dict) and "text" in response:
                response = response["text"]

            # TÄƒng cÆ°á»ng pháº£n há»“i vá»›i gá»£i Ã½ bÃ¡c sÄ©
            enhanced_response = self.enhance_response_with_doctor_suggestions(user_message, response)

            # Cáº­p nháº­t bá»™ nhá»› trÃ² chuyá»‡n
            try:
                self.memory.chat_memory.add_user_message(user_message)
                self.memory.chat_memory.add_ai_message(enhanced_response)
            except Exception as e:
                logger.warning(f"Memory update error: {e}")

            return enhanced_response
        except Exception as e:
            logger.error(f"Response generation error: {e}")
            return "Xin lá»—i, tÃ´i Ä‘ang gáº·p sá»± cá»‘. Vui lÃ²ng thá»­ láº¡i sau."

    def generate_streaming_response(self, user_message: str):
        """
        Táº¡o pháº£n há»“i streaming vá»›i ngá»¯ cáº£nh thÃ´ng minh.
        """
        try:
            # Sá»­ dá»¥ng smart context
            context = self.get_smart_context(user_message)
            
            # Láº¥y lá»‹ch sá»­ trÃ² chuyá»‡n
            chat_history = ""
            if self.memory.chat_memory.messages:
                recent_messages = self.memory.chat_memory.messages[-4:]
                for msg in recent_messages:
                    if hasattr(msg, 'content'):
                        role = "Human" if msg.__class__.__name__ == "HumanMessage" else "Assistant"
                        chat_history += f"{role}: {msg.content}\n"
            
            # Táº¡o prompt
            prompt = MEDICAL_SYSTEM_PROMPT.format(
                context=context,
                chat_history=chat_history,
                question=user_message
            )
            
            # Stream response tá»« LLM
            full_response = ""
            for chunk in self.streaming_llm.stream_response(prompt):
                full_response += chunk
                yield chunk
            
            # Sau khi stream xong, thÃªm gá»£i Ã½ bÃ¡c sÄ© náº¿u cáº§n
            doctor_suggestions = self._get_doctor_suggestions_for_streaming(user_message)
            if doctor_suggestions:
                yield "\n\n"  # Xuá»‘ng dÃ²ng
                for suggestion_chunk in doctor_suggestions:
                    yield suggestion_chunk
                    full_response += suggestion_chunk
            
            # Cáº­p nháº­t memory vá»›i response Ä‘áº§y Ä‘á»§
            try:
                self.memory.chat_memory.add_user_message(user_message)
                self.memory.chat_memory.add_ai_message(full_response)
            except Exception as e:
                logger.warning(f"Memory update error: {e}")
                
        except Exception as e:
            logger.error(f"Streaming error: {e}")
            yield "Xin lá»—i, tÃ´i Ä‘ang gáº·p sá»± cá»‘. Vui lÃ²ng thá»­ láº¡i sau."

    def _get_doctor_suggestions_for_streaming(self, user_message: str) -> List[str]:
        """
        Táº¡o gá»£i Ã½ bÃ¡c sÄ© dÆ°á»›i dáº¡ng chunks cho streaming.
        """
        try:
            message_lower = user_message.lower()
            suggestions = []
            
            # Náº¿u há»i vá» triá»‡u chá»©ng
            if any(word in message_lower for word in ["Ä‘au", "bá»‡nh", "triá»‡u chá»©ng", "khÃ¡m"]):
                doctors = self.suggest_doctors_for_symptoms(user_message, limit=3)
                if doctors:
                    suggestions.append("ğŸ©º **Gá»£i Ã½ bÃ¡c sÄ© phÃ¹ há»£p:**\n")
                    for i, doctor in enumerate(doctors, 1):
                        doctor_info = f"{i}. **BÃ¡c sÄ© {doctor['name']}** - {doctor['specialty']}\n"
                        doctor_info += f"   ğŸ“ {doctor['clinic']}, {doctor['province']}\n"
                        doctor_info += f"   ğŸ’° {doctor['price']}\n"
                        if doctor.get('suggested_reason'):
                            doctor_info += f"   âœ¨ {doctor['suggested_reason']}\n"
                        doctor_info += "\n"
                        suggestions.append(doctor_info)
            
            # Náº¿u há»i vá» chuyÃªn khoa
            elif any(word in message_lower for word in ["chuyÃªn khoa", "khoa"]):
                words = message_lower.split()
                for i, word in enumerate(words):
                    if word in ["chuyÃªn", "khoa"] and i < len(words) - 1:
                        specialty_name = words[i + 1]
                        doctors = self.find_doctors_by_specialty(specialty_name, limit=3)
                        if doctors:
                            suggestions.append(f"ğŸ‘¨â€âš•ï¸ **CÃ¡c bÃ¡c sÄ© chuyÃªn khoa {specialty_name}:**\n")
                            for j, doctor in enumerate(doctors, 1):
                                doctor_info = f"{j}. **BÃ¡c sÄ© {doctor['name']}**\n"
                                doctor_info += f"   ğŸ“ {doctor['clinic']}, {doctor['province']}\n"
                                doctor_info += f"   ğŸ’° {doctor['price']}\n\n"
                                suggestions.append(doctor_info)
                        break
            
            return suggestions
            
        except Exception as e:
            logger.warning(f"Error generating doctor suggestions for streaming: {e}")
            return []

    # ThÃªm method Ä‘á»ƒ debug vÃ  monitoring
    def get_system_stats(self) -> Dict:
        """
        Láº¥y thá»‘ng kÃª há»‡ thá»‘ng Ä‘á»ƒ monitoring.
        """
        stats = self.get_health_status()
        
        # ThÃªm thÃ´ng tin vá» vector store
        if self.vector_store and self.vector_store.vectorstore:
            try:
                # Äáº¿m sá»‘ documents theo loáº¡i
                all_docs = self.vector_store.vectorstore.docstore._dict
                type_counts = {}
                
                for doc_id, doc in all_docs.items():
                    doc_type = doc.metadata.get("type", "unknown")
                    type_counts[doc_type] = type_counts.get(doc_type, 0) + 1
                
                stats["vector_store_stats"] = {
                    "total_documents": len(all_docs),
                    "document_types": type_counts,
                    "specialty_mapping_size": len(getattr(self.vector_store, 'specialty_mapping', {}))
                }
            except Exception as e:
                stats["vector_store_stats"] = {"error": str(e)}
        
        return stats

    # ThÃªm method há»— trá»£ Ä‘á»ƒ debug context
    def debug_context_selection(self, user_message: str) -> Dict:
        """
        Debug method Ä‘á»ƒ xem AI Ä‘ang chá»n context nhÆ° tháº¿ nÃ o.
        """
        message_lower = user_message.lower()
        
        context_info = {
            "message": user_message,
            "detected_intent": "general",
            "keywords_found": [],
            "context_strategy": "general_search"
        }
        
        # PhÃ¢n tÃ­ch Ã½ Ä‘á»‹nh
        if any(word in message_lower for word in ["bÃ¡c sÄ©", "doctor", "bs"]):
            context_info["detected_intent"] = "doctor_inquiry"
            context_info["context_strategy"] = "doctor_focused"
            context_info["keywords_found"] = [word for word in ["bÃ¡c sÄ©", "doctor", "bs"] if word in message_lower]
        
        elif any(word in message_lower for word in ["chuyÃªn khoa", "khoa", "specialty"]):
            context_info["detected_intent"] = "specialty_inquiry"
            context_info["context_strategy"] = "specialty_focused"
            context_info["keywords_found"] = [word for word in ["chuyÃªn khoa", "khoa", "specialty"] if word in message_lower]
        
        elif any(word in message_lower for word in ["Ä‘au", "bá»‡nh", "triá»‡u chá»©ng", "khÃ¡m", "chá»¯a"]):
            context_info["detected_intent"] = "symptom_description"
            context_info["context_strategy"] = "symptom_to_doctor_matching"
            context_info["keywords_found"] = [word for word in ["Ä‘au", "bá»‡nh", "triá»‡u chá»©ng", "khÃ¡m", "chá»¯a"] if word in message_lower]
            
            # ThÃªm symptom keywords
            symptom_keywords = self._extract_symptom_keywords(user_message)
            if symptom_keywords:
                context_info["symptom_keywords"] = symptom_keywords
        
        return context_info

    # Method Ä‘á»ƒ test hiá»‡u suáº¥t cá»§a tá»«ng strategy
    def test_context_strategies(self, user_message: str) -> Dict:
        """
        Test cÃ¡c strategy khÃ¡c nhau Ä‘á»ƒ so sÃ¡nh hiá»‡u quáº£.
        """
        if self.vector_store.vectorstore is None:
            return {"error": "Vector store not available"}
        
        strategies = {
            "general": self._get_general_context(user_message),
            "doctor_focused": self._get_doctor_context(user_message),
            "specialty_focused": self._get_specialty_context(user_message),
            "symptom_focused": self._get_symptom_context(user_message),
            "smart": self.get_smart_context(user_message)
        }
        
        # Äáº¿m sá»‘ lÆ°á»£ng thÃ´ng tin vá» bÃ¡c sÄ©/chuyÃªn khoa trong má»—i strategy
        results = {}
        for strategy_name, context in strategies.items():
            doctor_mentions = context.lower().count("bÃ¡c sÄ©")
            specialty_mentions = context.lower().count("chuyÃªn khoa")
            context_length = len(context)
            
            results[strategy_name] = {
                "context_length": context_length,
                "doctor_mentions": doctor_mentions,
                "specialty_mentions": specialty_mentions,
                "relevance_score": (doctor_mentions + specialty_mentions) / max(context_length / 1000, 1),
                "context_preview": context[:200] + "..." if len(context) > 200 else context
            }
        
        return results
    # ThÃªm vÃ o class EnhancedMedicalChatbot

    def find_doctors_by_name(self, doctor_name: str) -> List[Dict]:
        """
        TÃ¬m bÃ¡c sÄ© theo tÃªn cá»¥ thá»ƒ.
        """
        if not self.vector_store.vectorstore:
            return []
        
        try:
            # TÃ¬m kiáº¿m vá»›i query cá»¥ thá»ƒ
            docs = self.vector_store.vectorstore.similarity_search(
                f"bÃ¡c sÄ© {doctor_name}",
                k=10
            )
            
            # Filter chá»‰ láº¥y documents vá» bÃ¡c sÄ©
            doctor_docs = []
            for doc in docs:
                if doc.metadata.get("type") == "doctor":
                    doctor_data = doc.metadata.get("data", {})
                    doctor_name_in_doc = f"{doctor_data.get('firstName', '')} {doctor_data.get('lastName', '')}".strip()
                    
                    # Kiá»ƒm tra Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng tÃªn
                    if doctor_name.lower() in doctor_name_in_doc.lower() or doctor_name_in_doc.lower() in doctor_name.lower():
                        doctor_docs.append({
                            "name": doctor_name_in_doc,
                            "specialty": doctor_data.get("specialty", "N/A"),
                            "clinic": doctor_data.get("clinic", "N/A"),
                            "province": doctor_data.get("province", "N/A"),
                            "price": doctor_data.get("price", "N/A"),
                            "payment": doctor_data.get("payment", "N/A"),
                            "note": doctor_data.get("note", "")[:200],
                            "full_data": doctor_data
                        })
            
            return doctor_docs
        
        except Exception as e:
            logger.error(f"Error finding doctors by name: {e}")
            return []

    def find_doctors_by_specialty(self, specialty_name: str, limit: int = 5) -> List[Dict]:
        """
        TÃ¬m bÃ¡c sÄ© theo chuyÃªn khoa cá»¥ thá»ƒ.
        """
        if not self.vector_store.vectorstore:
            return []
        
        try:
            # TÃ¬m kiáº¿m vá»›i nhiá»u query variant
            search_queries = [
                f"chuyÃªn khoa {specialty_name}",
                f"bÃ¡c sÄ© {specialty_name}",
                f"{specialty_name} bÃ¡c sÄ©",
                specialty_name
            ]
            
            all_docs = []
            for query in search_queries:
                docs = self.vector_store.vectorstore.similarity_search(query, k=8)
                all_docs.extend(docs)
            
            # Lá»c vÃ  xá»­ lÃ½ documents
            doctor_matches = []
            seen_doctors = set()
            
            for doc in all_docs:
                if doc.metadata.get("type") == "doctor":
                    doctor_data = doc.metadata.get("data", {})
                    doctor_id = doctor_data.get("id")
                    doctor_specialty = doctor_data.get("specialty", "").lower()
                    
                    # TrÃ¡nh duplicate
                    if doctor_id in seen_doctors:
                        continue
                    seen_doctors.add(doctor_id)
                    
                    # Kiá»ƒm tra Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng chuyÃªn khoa
                    if (specialty_name.lower() in doctor_specialty or 
                        doctor_specialty in specialty_name.lower() or
                        any(keyword in doctor_specialty for keyword in specialty_name.lower().split())):
                        
                        doctor_name = f"{doctor_data.get('firstName', '')} {doctor_data.get('lastName', '')}".strip()
                        doctor_matches.append({
                            "name": doctor_name,
                            "specialty": doctor_data.get("specialty", "N/A"),
                            "clinic": doctor_data.get("clinic", "N/A"),
                            "province": doctor_data.get("province", "N/A"),
                            "price": doctor_data.get("price", "N/A"),
                            "payment": doctor_data.get("payment", "N/A"),
                            "note": doctor_data.get("note", "")[:200],
                            "relevance_score": self._calculate_specialty_relevance(specialty_name, doctor_specialty),
                            "full_data": doctor_data
                        })
            
            # Sáº¯p xáº¿p theo Ä‘á»™ liÃªn quan
            doctor_matches.sort(key=lambda x: x["relevance_score"], reverse=True)
            
            return doctor_matches[:limit]
        
        except Exception as e:
            logger.error(f"Error finding doctors by specialty: {e}")
            return []

    def _calculate_specialty_relevance(self, query_specialty: str, doctor_specialty: str) -> float:
        """
        TÃ­nh Ä‘iá»ƒm Ä‘á»™ liÃªn quan giá»¯a chuyÃªn khoa query vÃ  chuyÃªn khoa cá»§a bÃ¡c sÄ©.
        """
        query_lower = query_specialty.lower()
        doctor_lower = doctor_specialty.lower()
        
        # Exact match
        if query_lower == doctor_lower:
            return 1.0
        
        # Substring match
        if query_lower in doctor_lower or doctor_lower in query_lower:
            return 0.8
        
        # Word overlap
        query_words = set(query_lower.split())
        doctor_words = set(doctor_lower.split())
        
        if query_words & doctor_words:  # CÃ³ tá»« chung
            overlap_ratio = len(query_words & doctor_words) / len(query_words | doctor_words)
            return 0.6 * overlap_ratio
        
        return 0.0

    def get_specialty_overview(self, specialty_name: str) -> Dict:
        """
        Láº¥y thÃ´ng tin tá»•ng quan vá» má»™t chuyÃªn khoa, bao gá»“m mÃ´ táº£ vÃ  danh sÃ¡ch bÃ¡c sÄ©.
        """
        if not self.vector_store.vectorstore:
            return {"error": "Vector store not available"}
        
        try:
            # TÃ¬m thÃ´ng tin vá» chuyÃªn khoa
            specialty_docs = self.vector_store.vectorstore.similarity_search(
                f"chuyÃªn khoa {specialty_name}",
                k=10
            )
            
            # TÃ¬m bÃ¡c sÄ© thuá»™c chuyÃªn khoa
            doctors = self.find_doctors_by_specialty(specialty_name, limit=10)
            
            # TÃ¬m thÃ´ng tin chi tiáº¿t vá» chuyÃªn khoa
            specialty_info = ""
            for doc in specialty_docs:
                if doc.metadata.get("type") in ["specialty", "specialty_detail"]:
                    specialty_info += doc.page_content + "\n"
            
            return {
                "specialty_name": specialty_name,
                "description": specialty_info.strip() if specialty_info else "KhÃ´ng cÃ³ thÃ´ng tin chi tiáº¿t",
                "doctors_count": len(doctors),
                "doctors": doctors,
                "related_info": [doc.page_content for doc in specialty_docs[:5] 
                            if doc.metadata.get("type") not in ["doctor"]]
            }
        
        except Exception as e:
            logger.error(f"Error getting specialty overview: {e}")
            return {"error": str(e)}

    def suggest_doctors_for_symptoms(self, symptoms: str, limit: int = 3) -> List[Dict]:
        """
        Äá» xuáº¥t bÃ¡c sÄ© dá»±a trÃªn triá»‡u chá»©ng mÃ´ táº£.
        """
        try:
            # TrÃ­ch xuáº¥t keywords tá»« triá»‡u chá»©ng
            symptom_keywords = self._extract_symptom_keywords(symptoms)
            
            if not symptom_keywords:
                return []
            
            suggested_doctors = []
            
            # TÃ¬m bÃ¡c sÄ© cho tá»«ng chuyÃªn khoa liÃªn quan
            for specialty in symptom_keywords:
                doctors = self.find_doctors_by_specialty(specialty, limit=2)
                for doctor in doctors:
                    doctor["suggested_reason"] = f"ChuyÃªn khoa {specialty} phÃ¹ há»£p vá»›i triá»‡u chá»©ng cá»§a báº¡n"
                    suggested_doctors.append(doctor)
            
            # Loáº¡i bá» duplicate vÃ  giá»›i háº¡n sá»‘ lÆ°á»£ng
            seen_doctors = set()
            unique_doctors = []
            
            for doctor in suggested_doctors:
                doctor_id = doctor.get("full_data", {}).get("id")
                if doctor_id not in seen_doctors:
                    seen_doctors.add(doctor_id)
                    unique_doctors.append(doctor)
            
            return unique_doctors[:limit]
        
        except Exception as e:
            logger.error(f"Error suggesting doctors for symptoms: {e}")
            return []

    # Method Ä‘á»ƒ tÃ­ch há»£p vÃ o generate_response
    def enhance_response_with_doctor_suggestions(self, user_message: str, base_response: str) -> str:
        """
        TÄƒng cÆ°á»ng pháº£n há»“i vá»›i gá»£i Ã½ bÃ¡c sÄ© cá»¥ thá»ƒ náº¿u phÃ¹ há»£p.
        """
        message_lower = user_message.lower()
        
        # Náº¿u ngÆ°á»i dÃ¹ng há»i vá» triá»‡u chá»©ng
        if any(word in message_lower for word in ["Ä‘au", "bá»‡nh", "triá»‡u chá»©ng", "khÃ¡m"]):
            doctors = self.suggest_doctors_for_symptoms(user_message, limit=3)
            if doctors:
                suggestion_text = "\n\nğŸ©º **Gá»£i Ã½ bÃ¡c sÄ© phÃ¹ há»£p:**\n"
                for i, doctor in enumerate(doctors, 1):
                    suggestion_text += f"{i}. **BÃ¡c sÄ© {doctor['name']}** - {doctor['specialty']}\n"
                    suggestion_text += f"   ğŸ“ {doctor['clinic']}, {doctor['province']}\n"
                    suggestion_text += f"   ğŸ’° {doctor['price']}\n"
                    if doctor.get('suggested_reason'):
                        suggestion_text += f"   âœ¨ {doctor['suggested_reason']}\n"
                    suggestion_text += "\n"
                
                return base_response + suggestion_text
        
        # Náº¿u ngÆ°á»i dÃ¹ng há»i vá» chuyÃªn khoa cá»¥ thá»ƒ
        elif any(word in message_lower for word in ["chuyÃªn khoa", "khoa"]):
            # TrÃ­ch xuáº¥t tÃªn chuyÃªn khoa tá»« cÃ¢u há»i
            # ÄÃ¢y lÃ  logic Ä‘Æ¡n giáº£n, cÃ³ thá»ƒ cáº£i thiá»‡n báº±ng NER
            words = message_lower.split()
            for i, word in enumerate(words):
                if word in ["chuyÃªn", "khoa"] and i < len(words) - 1:
                    specialty_name = words[i + 1]
                    doctors = self.find_doctors_by_specialty(specialty_name, limit=5)
                    if doctors:
                        suggestion_text = f"\n\nğŸ‘¨â€âš•ï¸ **CÃ¡c bÃ¡c sÄ© chuyÃªn khoa {specialty_name}:**\n"
                        for i, doctor in enumerate(doctors, 1):
                            suggestion_text += f"{i}. **BÃ¡c sÄ© {doctor['name']}**\n"
                            suggestion_text += f"   ğŸ“ {doctor['clinic']}, {doctor['province']}\n"
                            suggestion_text += f"   ğŸ’° {doctor['price']}\n\n"
                        
                        return base_response + suggestion_text
                    break
        
        return base_response

enhanced_chatbot = EnhancedMedicalChatbot()